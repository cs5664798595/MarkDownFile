createdAt: "2018-06-28T15:23:59.350Z"
updatedAt: "2018-06-28T15:28:19.987Z"
type: "MARKDOWN_NOTE"
folder: "28a1612eace96a999cc3"
title: "最佳论文"
content: '''
  # 最佳论文
  ## CVPR2018 的最佳论文Taskonomy: Disentangling Task Transfer Learning
  CVPR2018 的最佳论文（Best Paper Award）由斯坦福大学和 UC Berkeley 的 Amir R. Zamir 等人获得。他们提出了一个映射视觉任务空间的框架，通过计算不同任务的相关性来确定迁移学习方案，从而可以在保持准确率的同时，大大降低对数据、监督信息和计算资源的需求。
  
  最佳论文：Taskonomy: Disentangling Task Transfer Learning
  
  
  论文链接：http://taskonomy.stanford.edu/taskonomy_CVPR2018.pdf
  
  视觉任务之间是否相关？例如，能否使用曲面法线简化估计图像深度的过程？直觉上对这些问题的正面回答暗示着在各种视觉任务之间存在一种结构。了解这种结构具有巨大的价值；它是迁移学习背后的概念，且可为识别任务间的冗余提供了一种有理可依的方法，比如，为了在相关任务间无缝地重复使用监督或在一个系统中解决多个任务而不增加复杂度。
  
  我们提出了一种完全计算的方法来建模视觉任务的空间结构，通过在一个位于隐空间内的 26 个二维、2.5 维、三维和语义任务中寻找（一阶或更高阶）迁移学习依赖关系来实现。其成品是用于任务迁移学习的计算分类图。我们研究了这个结构的成果，比如出现的非平凡相关关系，并利用它们减少对标注数据的需求。比如，我们展示了解决一组 10 个任务所需的标注数据点总数可以减少约 2/3（与独立训练相比），同时保持性能几乎一致。我们提供了一套计算和探测这种分类结构的工具，包括一个求解器，用户可以用它来为其用例设计有效的监督策略。
  
  该项目也已开源并放出官方的 API 和 Demo：http://taskonomy.stanford.edu/
  
  会后，该论文的第一作者、斯坦福大学和加州大学伯克利分校的博士后研究员 Amir Roshan Zamir 告诉机器之心记者，「这篇论文主要围绕了当前机器学习系统最大的缺点，也就是需要很多标注数据才能完成它们想要的结果。人类是可以借鉴学到的不同技能，也就是迁移学习，你在第一盘棋中学到的技能可以用到第 10、第 100 盘棋，这篇论文的重点就是将这个概念带去机器学习、尤其是在感知（perception）这块儿。基本上你用你之前学的技能解决新的问题。」
  
  该论文的共同二作，斯坦福大学计算机科学系的现本科生/准博士生沈博魁告诉记者，他们的目标是找到不同任务之间的关联，这些任务比如说是深度感知（depth-perception）、surface normal estimation 之类的，发现这些关联之后就能用更少的数据来解决更多的任务。比如用边缘检测和 surface normal estimation 就能更好地学深度感知。
'''
tags: [
  "CVPR2018_的最佳论文Taskonomy:_Disentangling_Task_Transfer_Learning"
]
isStarred: false
isTrashed: false
